{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example model training for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Dense, Activation, Lambda, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for file in (os.listdir(DATA)):\n",
    "    with open(DATA + file) as f:\n",
    "        corpus += f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter strings to keep only a reduced set of characters, remove extraneous whitespaces and change everything to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [' '.join(re.sub('[^\\w .,\\'-/:]', ' ', s).split()).lower() for s in corpus if s.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum([len(x) for x in corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and reshape our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare tokenizer and \"reverse tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "nb_index = len(tokenizer.word_index) + 1# word_index starts at 1\n",
    "space_index = tokenizer.word_index[' ']\n",
    "\n",
    "X_raw = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "# flatten our corpus into a big list of encoded characters\n",
    "# note: we can do it this way because our whole corpus fits in memory\n",
    "X_raw = np.hstack(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the size of your segments with the `seg_size` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad our data with space characters so its length will be a multiple of `seg_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_raw = np.append(X_raw, np.full(seg_size - X_raw.shape[0] % seg_size, space_index))\n",
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reshape our data for training:\n",
    "- X: overlapping sequences of `seg_size` characters\n",
    "- Y: the following value for each sequence\n",
    "\n",
    "Note that we one-hot encode everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((X_raw.shape[0], seg_size, nb_index), dtype=np.bool)\n",
    "Y = np.zeros((X_raw.shape[0], nb_index), dtype=np.bool)\n",
    "\n",
    "for i in range(0, X_raw.shape[0] - seg_size):\n",
    "    for j in range(seg_size):\n",
    "        X[i][j][int(X_raw[i + j])] = 1\n",
    "    Y[i][int(X_raw[i + seg_size])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model is heavily inspired by http://karpathy.github.io/2015/05/21/rnn-effectiveness/ and https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "# You can change these to play with different network shapes\n",
    "RNN_SIZE= 64\n",
    "NUM_LAYERS = 2 \n",
    "BATCH_SIZE = 256\n",
    "DROPOUT = 0.2\n",
    "\n",
    "inputl = Input(shape=(seg_size, nb_index))\n",
    "x= inputl\n",
    "\n",
    "for i in range(NUM_LAYERS-1):\n",
    "    x = LSTM(RNN_SIZE, return_sequences=True)(x)\n",
    "x = LSTM(RNN_SIZE, return_sequences=False)(x)\n",
    "    \n",
    "x = Dropout(DROPOUT)(x)\n",
    "    \n",
    "x = Dense(nb_index)(x)\n",
    "x = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(inputl, x)\n",
    "autoencoder.compile(optimizer='RMSprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions can be used to switch back and forth between a string and its encoded form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_string(s, segsize, num_classes):\n",
    "    Xt = np.array(tokenizer.texts_to_sequences([s]))\n",
    "    Xt = np.append(np.full(segsize - Xt.shape[1] % segsize, space_index), Xt) # pad beginning with spaces\n",
    "    Xt = keras.utils.to_categorical(Xt, num_classes=num_classes)\n",
    "    Xt = Xt.reshape(segsize, num_classes)\n",
    "    return Xt\n",
    "    \n",
    "def decode_string(s):\n",
    "    return [reverse_word_map[x] for x in np.argmax(s, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an utility function to export the model to filesystem. The model can be saved as a single file or with structure and weights separated.\n",
    "The function also export a dictionnary to convert model outputs to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def export(model, basepath, split=False):\n",
    "    if not os.path.exists(basepath):\n",
    "        os.makedirs(basepath)\n",
    "        \n",
    "    if not split:\n",
    "        model.save(basepath + '/model.h5' )\n",
    "    else:\n",
    "        model.save_weights(basepath + '/model.hdf5')\n",
    "        with open(basepath + '/model.json', 'w') as f:\n",
    "            f.write(model.to_json())\n",
    "\n",
    "    with open(basepath + '/dict.json', 'w') as fp:\n",
    "        json.dump(tokenizer.word_index, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you want to load an already existing model instead of starting from scratch, you can do it here for example by uncommenting the following line and setting the adqueate path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autoencoder = keras.models.load_model('mymodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some utility methods to help monitor the progress of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(model, base, size):\n",
    "    for i in range(size):\n",
    "        d = np.argmax(autoencoder.predict(np.array([base[-30:]]))[0])\n",
    "        r = np.zeros(nb_index)\n",
    "        r[d] = 1\n",
    "        base = np.vstack((base, r))\n",
    "    return decode_string(base) \n",
    "\n",
    "def sample_string(model, base, size):\n",
    "    e = encode_string(base, seg_size, nb_index)\n",
    "    return sample(model, e, size)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for 10 epoch, saving the current version and outputing generated text after each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('-' * 50)\n",
    "\n",
    "print(*decode_string(X[0]), sep='')\n",
    "print(*sample(autoencoder, X[0], 20), sep='')\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "print('ceci est un ')\n",
    "print(*sample_string(autoencoder, 'ceci est un ', 20), sep='')\n",
    "\n",
    "print()\n",
    "\n",
    "for iteration in range(10):\n",
    "    print('=' * 50)\n",
    "    print('Iteration', iteration)\n",
    "\n",
    "    autoencoder.fit(X, Y,\n",
    "                    epochs=1,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)\n",
    "\n",
    "    # let's generate some sample strings to see how training is going\n",
    "    print('-' * 50)\n",
    "\n",
    "    print(*decode_string(X[0]), sep='')\n",
    "    print(*sample(autoencoder, X[0], 20), sep='')\n",
    "\n",
    "    print('-' * 50)\n",
    "\n",
    "    print('ceci est un ')\n",
    "    print(*sample_string(autoencoder, 'ceci est un ', 20), sep='')\n",
    "\n",
    "    print()\n",
    "    \n",
    "    export(autoencoder, './model_' + str(datetime.datetime.now()), split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}